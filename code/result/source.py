import cv2
import mediapipe as mp
import numpy as np
import time
from datetime import datetime
import json
import sys
import os
import face_recognition
import threading
import tkinter as tk
from tkinter import ttk, messagebox, scrolledtext
from PIL import Image, ImageTk
from pathlib import Path
import queue
import time
import subprocess

tts_queue = queue.Queue()

# TTS import
try:
    from gtts import gTTS
    TTS_AVAILABLE = True
except ImportError:
    TTS_AVAILABLE = False

class SimpleExamSupervisor:
    """ë‹¨ìˆœí™”ëœ AI ì‹œí—˜ ê°ë…ê´€ - ì›ë³¸ ê¸°ëŠ¥ ì™„ì „ ë³´ì¡´"""
    
    def __init__(self):
        self.setup_config()
        self.setup_mediapipe()
        self.setup_variables()
        self.setup_gui()
        
        # ì¹´ë©”ë¼ ìƒíƒœ
        self.cap = None
        self.is_running = False
        self.current_frame = None
        
        print("ğŸ”’ AI ì‹œí—˜ ê°ë…ê´€ ì‹œìŠ¤í…œ v2.6 (ë‹¨ìˆœí™”) ì´ˆê¸°í™” ì™„ë£Œ")
        
    def setup_config(self):
        default_config = {
            "camera": {"index": 0, "width": 640, "height": 480, "fps": 20, "mirror": True},
            "detection": {"x_threshold": 0.15, "y_threshold": 0.5, "sustained_time": 2.0, 
                         "gaze_margin": 0.6, "face_lost_threshold": 1.0},
            "identity": {"dataset_path": "./dataset", "tolerance": 0.4, "max_attempts": 5,
                        "blink_threshold": 0.21, "blink_required": 2, "blink_detection_duration": 6},
            "system": {"baseline_frames": 30, "save_video": True, "log_path": "./logs", "max_warnings": 5}
        }
        
        config_path = "config.json"
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                for key in default_config:
                    if key not in config:
                        config[key] = default_config[key]
                    else:
                        for subkey in default_config[key]:
                            if subkey not in config[key]:
                                config[key][subkey] = default_config[key][subkey]
            except:
                config = default_config
        else:
            config = default_config
            
        self.config = config
        # ì„¤ì •ê°’ ì ìš©
        self.CAMERA_INDEX = config["camera"]["index"]
        self.CAMERA_WIDTH = config["camera"]["width"]
        self.CAMERA_HEIGHT = config["camera"]["height"]
        self.CAMERA_FPS = config["camera"]["fps"]
        self.MIRROR_CAMERA = config["camera"]["mirror"]
        
        self.X_THRESHOLD = config["detection"]["x_threshold"]
        self.Y_THRESHOLD = config["detection"]["y_threshold"]
        self.SUSTAINED_TIME = config["detection"]["sustained_time"]
        self.GAZE_MARGIN = config["detection"]["gaze_margin"]
        self.FACE_LOST_THRESHOLD = config["detection"]["face_lost_threshold"]
        
        self.DATASET_PATH = config["identity"]["dataset_path"]
        self.FACE_TOLERANCE = config["identity"]["tolerance"]
        self.MAX_IDENTITY_ATTEMPTS = config["identity"]["max_attempts"]
        self.BLINK_THRESHOLD = config["identity"]["blink_threshold"]
        self.BLINK_REQUIRED = config["identity"]["blink_required"]
        self.BLINK_DETECTION_DURATION = config["identity"]["blink_detection_duration"]
        
        self.BASELINE_FRAMES = config["system"]["baseline_frames"]
        self.SAVE_VIDEO = config["system"]["save_video"]
        self.LOG_PATH = config["system"]["log_path"]
        self.MAX_WARNINGS = config["system"]["max_warnings"]
        
    def setup_mediapipe(self):
        """MediaPipe ì´ˆê¸°í™”"""
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            refine_landmarks=True, static_image_mode=False, max_num_faces=2,
            min_detection_confidence=0.5, min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
        # ëœë“œë§ˆí¬ í¬ì¸íŠ¸ë“¤
        self.NOSE_TIP = 1
        self.LEFT_EYE_LEFT = 33
        self.RIGHT_EYE_RIGHT = 263
        self.LEFT_MOUTH = 61
        self.RIGHT_MOUTH = 291
        self.CHIN = 18
        
        self.LEFT_EYE = [33, 160, 158, 133, 153, 144]
        self.RIGHT_EYE = [362, 387, 385, 263, 373, 380]
        self.LEFT_EYE_EAR = [362, 385, 387, 263, 373, 380]
        self.RIGHT_EYE_EAR = [33, 160, 158, 133, 153, 144]
        self.MAX_EAR_HISTORY = 100
        
    def setup_variables(self):
        """ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”"""
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.system_phase = "IDLE"
        self.authenticated_user = None
        self.exam_start_time = None
        self.exam_terminated = False
        self.termination_reason = ""
        
        # ê²½ê³  ì‹œìŠ¤í…œ
        self.total_warnings = 0
        self.head_warnings = 0
        self.gaze_warnings = 0
        
        # ì•„ì´íŠ¸ë˜í‚¹ ë³€ìˆ˜ë“¤
        self.gaze_baseline = None
        self.frame_count = 0
        self.baseline_sum = 0
        self.last_gaze_violation_time = 0
        
        # ì–¼êµ´ ì¶”ì  ë³€ìˆ˜ë“¤
        self.last_face_landmarks = None
        self.face_lost_time = 0
        
        # ë¡œê¹… ì‹œìŠ¤í…œ
        self.violation_log = []
        self.total_violations = 0
        self.identity_attempts = 0
        
        # ìœ„ë°˜ ìƒíƒœë“¤
        self.reset_violation_states()
        
        # í´ë” ìƒì„±
        Path(self.DATASET_PATH).mkdir(exist_ok=True)
        Path(self.LOG_PATH).mkdir(exist_ok=True)
        
    def create_gui(self):
        """ê°„ë‹¨í•œ GUI ìƒì„±"""
        # ë©”ì¸ ì»¨í…Œì´ë„ˆ
        main_frame = tk.Frame(self.root)
        main_frame.pack(fill="both", expand=True, padx=10, pady=10)
        
        # ì™¼ìª½: ì¹´ë©”ë¼
        left_frame = tk.Frame(main_frame)
        left_frame.pack(side="left", fill="both", expand=True, padx=(0, 10))
        
        # ì¹´ë©”ë¼ í‘œì‹œ
        camera_frame = ttk.LabelFrame(left_frame, text="ğŸ“¹ ì‹¤ì‹œê°„ ì¹´ë©”ë¼")
        camera_frame.pack(fill="both", expand=True, pady=(0, 10))
        
        self.camera_label = tk.Label(camera_frame, text="ì¹´ë©”ë¼ ëŒ€ê¸° ì¤‘...", 
                                   bg="black", fg="white", font=("Arial", 14))
        self.camera_label.pack(fill="both", expand=True, padx=10, pady=10)
        
        # ìƒíƒœ í‘œì‹œ
        status_frame = ttk.LabelFrame(left_frame, text="ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        status_frame.pack(fill="x")
        
        # ìƒíƒœ ë¼ë²¨ë“¤ ìƒì„±
        self.create_status_labels(status_frame)
        
        # ì˜¤ë¥¸ìª½: ì œì–´ ë° ë¡œê·¸
        right_frame = tk.Frame(main_frame, width=350)
        right_frame.pack(side="right", fill="y")
        right_frame.pack_propagate(False)
        
        # ì œì–´ ë²„íŠ¼ë“¤
        self.create_control_buttons(right_frame)
        
        # ë¡œê·¸
        self.create_log_panel(right_frame)
        
    def setup_gui(self):
        """GUI ì´ˆê¸°í™”"""
        self.root = tk.Tk()
        self.root.title("ğŸ¤– AI ì‹œí—˜ ê°ë…ê´€ v2.6 (ë‹¨ìˆœí™”)")
        self.root.geometry("1200x800")
        
        self.create_gui()
        
    def create_status_labels(self, parent):
        """ìƒíƒœ ë¼ë²¨ ìƒì„±"""
        # 2ì—´ êµ¬ì„±
        info_frame = tk.Frame(parent)
        info_frame.pack(fill="x", padx=10, pady=10)
        
        left_col = tk.Frame(info_frame)
        left_col.pack(side="left", fill="both", expand=True)
        right_col = tk.Frame(info_frame)
        right_col.pack(side="right", fill="both", expand=True)
        
        # ìƒíƒœ ì•„ì´í…œë“¤ (GUI ë¼ë²¨ì— ì§ì ‘ ì ‘ê·¼)
        self.user_label = self.create_status_item(left_col, "ğŸ‘¤ ì‚¬ìš©ì:", "ë¯¸ì¸ì¦")
        self.phase_label = self.create_status_item(left_col, "ğŸ”„ ë‹¨ê³„:", "ëŒ€ê¸° ì¤‘")
        self.time_label = self.create_status_item(left_col, "â° ì‹œí—˜ ì‹œê°„:", "00:00:00")
        self.face_label = self.create_status_item(right_col, "ğŸ‘¥ ì–¼êµ´:", "0ëª…")
        self.head_label = self.create_status_item(right_col, "ğŸ¯ ê³ ê°œ:", "ì •ë©´")
        self.gaze_label = self.create_status_item(right_col, "ğŸ‘ ì‹œì„ :", "ëŒ€ê¸° ì¤‘")
        self.warning_label = self.create_status_item(right_col, "âš ï¸ ê²½ê³ :", "0/5")
        
    def create_status_item(self, parent, label_text, default_value):
        """ìƒíƒœ ì•„ì´í…œ ìƒì„±"""
        frame = tk.Frame(parent)
        frame.pack(fill="x", pady=2)
        
        tk.Label(frame, text=label_text, width=12, anchor="w").pack(side="left")
        value_label = tk.Label(frame, text=default_value, anchor="w", 
                              font=("Arial", 9, "bold"))
        value_label.pack(side="left")
        
        return value_label
        
    def create_control_buttons(self, parent):
        """ì œì–´ ë²„íŠ¼ ìƒì„±"""
        control_frame = ttk.LabelFrame(parent, text="ğŸ›ï¸ ì‹œìŠ¤í…œ ì œì–´")
        control_frame.pack(fill="x", pady=(0, 10), padx=5)
        
        # ë²„íŠ¼ë“¤
        tk.Button(control_frame, text="â–¶ï¸ ì‹œìŠ¤í…œ ì‹œì‘", command=self.start_system,
                 bg="#28a745", fg="white", font=("Arial", 11, "bold")).pack(fill="x", pady=5, padx=10)
        
        tk.Button(control_frame, text="ğŸ‘¤ ì‹ ì› í™•ì¸", command=self.start_identity,
                 bg="#17a2b8", fg="white", font=("Arial", 11)).pack(fill="x", pady=5, padx=10)
        
        tk.Button(control_frame, text="ğŸ” ì‹œí—˜ ê°ë…", command=self.start_monitoring,
                 bg="#ffc107", fg="black", font=("Arial", 11)).pack(fill="x", pady=5, padx=10)
        
        tk.Button(control_frame, text="â¹ï¸ ì‹œìŠ¤í…œ ì¤‘ì§€", command=self.stop_system,
                 bg="#dc3545", fg="white", font=("Arial", 11)).pack(fill="x", pady=5, padx=10)
        
    def create_log_panel(self, parent):
        """ë¡œê·¸ íŒ¨ë„"""
        log_frame = ttk.LabelFrame(parent, text="ğŸ“ ì‹¤ì‹œê°„ ë¡œê·¸")
        log_frame.pack(fill="both", expand=True, padx=5)
        
        self.log_text = scrolledtext.ScrolledText(log_frame, height=20, wrap=tk.WORD, 
                                                font=("Consolas", 9))
        self.log_text.pack(fill="both", expand=True, padx=10, pady=10)
        
    # =====================================
    # ë©”ì¸ ë¡œì§
    # =====================================
    
    def start_system(self):
        """ì‹œìŠ¤í…œ ì‹œì‘"""
        if self.is_running:
            return
            
        # ì¹´ë©”ë¼ ì°¾ê¸°
        self.cap = self.find_camera()
        if self.cap is None:
            messagebox.showerror("ì˜¤ë¥˜", "ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
            
        self.is_running = True
        self.log_message("ì‹œìŠ¤í…œì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.", "SUCCESS")
        
        # ë©”ì¸ ë£¨í”„ ì‹œì‘ (ë‹¨ì¼ íƒ€ì´ë¨¸)
        self.update_loop()
        
    def find_camera(self):
        """ì¹´ë©”ë¼ ì°¾ê¸°"""
        camera_indices = [self.CAMERA_INDEX] + [i for i in range(5) if i != self.CAMERA_INDEX]
        
        for camera_idx in camera_indices:
            try:
                cap = cv2.VideoCapture(camera_idx)
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.CAMERA_WIDTH)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.CAMERA_HEIGHT)
                cap.set(cv2.CAP_PROP_FPS, self.CAMERA_FPS)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                
                if cap.isOpened():
                    ret, frame = cap.read()
                    if ret:
                        self.log_message(f"âœ… ì¹´ë©”ë¼ {camera_idx}ë²ˆ ì—°ê²° ì„±ê³µ ({self.CAMERA_WIDTH}x{self.CAMERA_HEIGHT}@{self.CAMERA_FPS}fps)", "SUCCESS")
                        return cap
                    cap.release()
            except:
                continue
        return None
        
    def update_loop(self):
        """ë©”ì¸ ì—…ë°ì´íŠ¸ ë£¨í”„"""
        if not self.is_running or self.cap is None:
            return
            
        ret, frame = self.cap.read()
        if not ret:
            self.root.after(50, self.update_loop)
            return
            
        if self.MIRROR_CAMERA:
            frame = cv2.flip(frame, 1)
            
        self.current_frame = frame.copy()
        
        # ë‹¨ê³„ë³„ ì²˜ë¦¬
        if self.system_phase == "IDENTITY_CHECK":
            self.process_identity_frame(frame)
        elif self.system_phase == "EXAM_MONITORING":
            self.process_monitoring_frame(frame)
            
        # GUI ì—…ë°ì´íŠ¸ (ì§ì ‘ í˜¸ì¶œ)
        self.update_camera_display(frame)
        self.update_status_display()
        
        # ë‹¤ìŒ í”„ë ˆì„ ìŠ¤ì¼€ì¤„ë§
        self.root.after(33, self.update_loop)  # ~30 FPS
        
    def update_camera_display(self, frame):
        """ì¹´ë©”ë¼ í™”ë©´ ì—…ë°ì´íŠ¸"""
        try:
            # BGR to RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # í¬ê¸° ì¡°ì •
            display_width = 600
            display_height = 450
            frame_resized = cv2.resize(frame_rgb, (display_width, display_height))
            
            # PIL ë³€í™˜
            image = Image.fromarray(frame_resized)
            photo = ImageTk.PhotoImage(image)
            
            # ë¼ë²¨ ì—…ë°ì´íŠ¸
            self.camera_label.configure(image=photo, text="")
            self.camera_label.image = photo  # ì°¸ì¡° ìœ ì§€
            
        except Exception as e:
            pass
            
    def update_status_display(self):
        """ìƒíƒœ ì •ë³´ ì§ì ‘ ì—…ë°ì´íŠ¸"""
        # ì‚¬ìš©ì ìƒíƒœ
        if self.authenticated_user:
            self.user_label.configure(text=self.authenticated_user, fg="green")
        else:
            self.user_label.configure(text="ë¯¸ì¸ì¦", fg="red")
            
        # ë‹¨ê³„ ìƒíƒœ
        self.phase_label.configure(text=self.system_phase)
        
        # ì‹œí—˜ ì‹œê°„
        if self.exam_start_time:
            elapsed = int(time.time() - self.exam_start_time)
            hours = elapsed // 3600
            minutes = (elapsed % 3600) // 60
            seconds = elapsed % 60
            self.time_label.configure(text=f"{hours:02d}:{minutes:02d}:{seconds:02d}")
            
        # ê²½ê³  ìƒíƒœ
        color = "red" if self.total_warnings >= self.MAX_WARNINGS else "orange" if self.total_warnings > 0 else "green"
        self.warning_label.configure(text=f"{self.total_warnings}/{self.MAX_WARNINGS}", fg=color)
        
    # =====================================
    # ì‹ ì› í™•ì¸
    # =====================================
    
    def start_identity(self):
        """ì‹ ì› í™•ì¸ ì‹œì‘"""
        if not self.is_running:
            messagebox.showwarning("ê²½ê³ ", "ì‹œìŠ¤í…œì„ ë¨¼ì € ì‹œì‘í•˜ì„¸ìš”!")
            return
            
        # ë°ì´í„°ì…‹ í™•ì¸
        dataset_files = list(Path(self.DATASET_PATH).glob("*.jpg")) + \
                       list(Path(self.DATASET_PATH).glob("*.jpeg")) + \
                       list(Path(self.DATASET_PATH).glob("*.png"))
        
        if not dataset_files:
            messagebox.showwarning("ê²½ê³ ", "ë°ì´í„°ì…‹ í´ë”ì— ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        self.system_phase = "IDENTITY_CHECK"
        self.identity_attempts = 0
        self.log_message("ğŸ” ì‹ ì› í™•ì¸ ì‹œì‘")
        
        # ê¹œë¹¡ì„ ê°ì§€ ì‹œì‘
        self.start_blink_detection()
        
    def start_blink_detection(self):
        """ê¹œë¹¡ì„ ê°ì§€ ì‹œì‘"""
        self.identity_attempts += 1
        self.blink_count = 0
        self.blink_flag = False
        self.blink_start_time = time.time()
        self.blink_detection_active = True
        
        self.log_message(f"ğŸ‘ {self.identity_attempts}ë²ˆì§¸ ì‹œë„: {self.BLINK_DETECTION_DURATION}ì´ˆ ë™ì•ˆ {self.BLINK_REQUIRED}íšŒ ê¹œë¹¡ì´ì„¸ìš”")
        speak_tts("ì‹ ì› ì¡°íšŒë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ë°”ë¼ë´ ì£¼ì„¸ìš”.")
        
    def process_identity_frame(self, frame):
        """ì‹ ì› í™•ì¸ í”„ë ˆì„ ì²˜ë¦¬"""
        if not hasattr(self, 'blink_detection_active') or not self.blink_detection_active:
            return
            
        # MediaPipe ì²˜ë¦¬
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        with self.mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True,
                                       min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:
            results = face_mesh.process(rgb)
            ear = None
            
            if results.multi_face_landmarks:
                for face_landmarks in results.multi_face_landmarks:
                    landmarks = face_landmarks.landmark
                    
                    # EAR ê³„ì‚°
                    left_ear = self.calculate_ear(landmarks, self.LEFT_EYE_EAR)
                    right_ear = self.calculate_ear(landmarks, self.RIGHT_EYE_EAR)
                    ear = (left_ear + right_ear) / 2.0
                    
                    # ê¹œë¹¡ì„ ê°ì§€
                    if ear < self.BLINK_THRESHOLD and not self.blink_flag:
                        self.blink_count += 1
                        self.blink_flag = True
                        self.log_message(f"ğŸ‘ ê¹œë¹¡ì„ ê°ì§€! ì´ {self.blink_count}íšŒ")
                        
                    elif ear >= self.BLINK_THRESHOLD:
                        self.blink_flag = False
                        
            # í™”ë©´ì— ìƒíƒœ í‘œì‹œ
            elapsed_time = time.time() - self.blink_start_time
            remaining_time = max(0, self.BLINK_DETECTION_DURATION - elapsed_time)
            
            cv2.putText(frame, f"Blinks: {self.blink_count}/{self.BLINK_REQUIRED}", 
                       (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            cv2.putText(frame, f"Time: {remaining_time:.1f}s", 
                       (30, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
            
            if ear is not None:
                color = (0, 255, 0) if ear >= self.BLINK_THRESHOLD else (0, 0, 255)
                cv2.putText(frame, f"EAR: {ear:.3f}", 
                           (30, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
                        
        # ì‹œê°„ í™•ì¸
        if time.time() - self.blink_start_time > self.BLINK_DETECTION_DURATION:
            self.complete_blink_detection()
            
    def complete_blink_detection(self):
        """ê¹œë¹¡ì„ ê°ì§€ ì™„ë£Œ"""
        self.blink_detection_active = False
        
        if self.blink_count >= self.BLINK_REQUIRED and self.current_frame is not None:
            self.log_message(f"âœ… ì‹¤ì œ ì‚¬ëŒ íŒë³„ë¨! ({self.blink_count}íšŒ)", "SUCCESS")
            self.log_message("ğŸ” ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬ ì¤‘...")
            
            # ì–¼êµ´ ë¹„êµ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"identity_{timestamp}.png"
            cv2.imwrite(filename, self.current_frame)
            
            # ì›ë³¸ ì–¼êµ´ ë¹„êµ í•¨ìˆ˜ ì‚¬ìš©
            matched_name = self.compare_with_dataset(filename)
            
            if matched_name:
                self.authenticated_user = matched_name
                self.log_message(f"ğŸ‰ ì¸ì¦ ì„±ê³µ! {matched_name}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤.", "SUCCESS")
                self.system_phase = "IDLE"
                speak_tts(f"{matched_name}ë‹˜, ì‹ ì› í™•ì¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                self.log_message(f"âŒ ì–¼êµ´ ì¸ì¦ ì‹¤íŒ¨ ({self.identity_attempts}/{self.MAX_IDENTITY_ATTEMPTS})", "ERROR")
                if self.identity_attempts < self.MAX_IDENTITY_ATTEMPTS:
                    self.log_message(f"ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”. ë‚¨ì€ íšŸìˆ˜: {self.MAX_IDENTITY_ATTEMPTS - self.identity_attempts}íšŒ")
                    self.start_blink_detection()  # ì¬ì‹œë„
                else:
                    self.log_message("âŒ ì‹ ì› í™•ì¸ ì‹¤íŒ¨: ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼", "ERROR")
                    self.system_phase = "IDLE"
                    
            try:
                os.remove(filename)
            except:
                pass
        else:
            self.log_message(f"âŒ ì‚¬ì§„ìœ¼ë¡œ íŒë³„ë¨ (ëˆˆ ê¹œë¹¡ì„ {self.blink_count}íšŒ < {self.BLINK_REQUIRED}íšŒ)", "ERROR")
            self.log_message("ì‹¤ì œ ì‚¬ëŒì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            if self.identity_attempts < self.MAX_IDENTITY_ATTEMPTS:
                self.start_blink_detection()  # ì¬ì‹œë„
            else:
                self.log_message("âŒ ì‹ ì› í™•ì¸ ì‹¤íŒ¨: ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼", "ERROR")
                self.system_phase = "IDLE"
                
    # =====================================
    #               ì‹œí—˜ ê°ë…
    # =====================================
    
    def start_monitoring(self):
        """ì‹œí—˜ ê°ë… ì‹œì‘"""
        if not self.authenticated_user:
            messagebox.showwarning("ê²½ê³ ", "ì‹ ì› í™•ì¸ì„ ë¨¼ì € ì™„ë£Œí•˜ì„¸ìš”!")
            return
            
        self.system_phase = "EXAM_MONITORING"
        self.exam_start_time = time.time()
        self.exam_terminated = False
        
        # ìƒíƒœ ì´ˆê¸°í™”
        self.reset_violation_states()
        self.total_warnings = 0
        self.head_warnings = 0
        self.gaze_warnings = 0
        self.violation_log = []
        self.total_violations = 0
        
        # ì‹œì„  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì´ˆê¸°í™”
        self.gaze_baseline = None
        self.frame_count = 0
        self.baseline_sum = 0
        
        self.log_message("ğŸ“ ì‹œí—˜ ê°ë… ì‹œì‘", "SUCCESS")
        self.log_message(f"ì‘ì‹œì: {self.authenticated_user}", "SUCCESS")
        self.log_message("ì‹¤ì‹œê°„ ë¶€ì •í–‰ìœ„ íƒì§€ ì‹œì‘...")
        speak_tts("ì‹œí—˜ ê°ë…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    def process_monitoring_frame(self, frame):
        """ì‹œí—˜ ê°ë… í”„ë ˆì„ ì²˜ë¦¬"""
        if self.exam_terminated:
            return
            
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        img_h, img_w = frame.shape[:2]
        
        results = self.face_mesh.process(frame_rgb)
        
        face_count = 0
        head_direction = "No Face"
        x_ratio, y_ratio = 0, 0
        gaze_ratio = 1
        
        if results.multi_face_landmarks:
            face_count = len(results.multi_face_landmarks)
            
            # ì²« ë²ˆì§¸ ì–¼êµ´ ë¶„ì„
            best_face = results.multi_face_landmarks[0]
            current_landmarks = self.get_landmarks_coords(best_face, img_w, img_h)
            
            # ë¨¸ë¦¬ ë°©í–¥
            head_direction, x_ratio, y_ratio = self.get_head_direction(current_landmarks, img_w, img_h)
            
            # ì‹œì„  ë¶„ì„
            landmarks_normalized = [(lm.x, lm.y) for lm in best_face.landmark]
            gaze_left = self.get_gaze_ratio(self.LEFT_EYE, landmarks_normalized, frame, gray)
            gaze_right = self.get_gaze_ratio(self.RIGHT_EYE, landmarks_normalized, frame, gray)
            current_gaze = (gaze_left + gaze_right) / 2
            
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì²˜ë¦¬
            if self.frame_count < self.BASELINE_FRAMES:
                self.baseline_sum += current_gaze
                self.frame_count += 1
                
                if self.frame_count == self.BASELINE_FRAMES:
                    self.gaze_baseline = self.baseline_sum / self.BASELINE_FRAMES
                    self.log_message(f"âœ… ì‹œì„  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ! (ê¸°ì¤€ê°’: {self.gaze_baseline:.2f})", "SUCCESS")
                    speak_tts("ì‹œí—˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    
                gaze_ratio = current_gaze
            else:
                gaze_ratio = current_gaze
                
        # GUI ìƒíƒœ ì§ì ‘ ì—…ë°ì´íŠ¸
        self.face_label.configure(text=f"{face_count}ëª…", 
                                fg="green" if face_count == 1 else "red")
        
        if head_direction == "Forward":
            self.head_label.configure(text="ì •ë©´", fg="green")
        elif head_direction == "No Face":
            self.head_label.configure(text="ê°ì§€ ì•ˆë¨", fg="red")
        else:
            self.head_label.configure(text=head_direction, fg="orange")
            
        # ì‹œì„  ìƒíƒœ ì—…ë°ì´íŠ¸
        if self.gaze_baseline is None:
            progress = (self.frame_count / self.BASELINE_FRAMES) * 100
            self.gaze_label.configure(text=f"ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘ {progress:.0f}%", fg="blue")
        else:
            if gaze_ratio != 1:
                current_gaze_abnormal = (gaze_ratio < self.gaze_baseline - self.GAZE_MARGIN or 
                                       gaze_ratio > self.gaze_baseline + self.GAZE_MARGIN)
                if current_gaze_abnormal:
                    direction = "ì™¼ìª½" if gaze_ratio < self.gaze_baseline else "ì˜¤ë¥¸ìª½"
                    self.gaze_label.configure(text=f"{direction} ì´íƒˆ", fg="orange")
                else:
                    self.gaze_label.configure(text="ì •ë©´", fg="green")
            else:
                self.gaze_label.configure(text="ì •ë©´", fg="green")
                    
        # ìœ„ë°˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.update_violation_states(face_count, head_direction, gaze_ratio)
        
        # í™”ë©´ì— ì •ë³´ í‘œì‹œ
        self.draw_status_info(frame, face_count, head_direction, gaze_ratio, x_ratio, y_ratio)
        
    def stop_system(self):
        """ì‹œìŠ¤í…œ ì¤‘ì§€"""
        self.is_running = False
        if self.cap:
            self.cap.release()
        self.log_message("ì‹œìŠ¤í…œì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.", "WARNING")
        
    # =====================================
    #         í•µì‹¬ ë¶€ì •í–‰ìœ„ íƒì§€!
    # =====================================
    
    def calculate_ear(self, landmarks, eye_indices):
        """EAR ê³„ì‚°"""
        try:
            left = np.array([landmarks[eye_indices[0]].x, landmarks[eye_indices[0]].y])
            right = np.array([landmarks[eye_indices[3]].x, landmarks[eye_indices[3]].y])
            top = (np.array([landmarks[eye_indices[1]].x, landmarks[eye_indices[1]].y]) +
                   np.array([landmarks[eye_indices[2]].x, landmarks[eye_indices[2]].y])) / 2
            bottom = (np.array([landmarks[eye_indices[4]].x, landmarks[eye_indices[4]].y]) +
                      np.array([landmarks[eye_indices[5]].x, landmarks[eye_indices[5]].y])) / 2
            
            horizontal = np.linalg.norm(left - right)
            vertical = np.linalg.norm(top - bottom)
            
            return vertical / horizontal if horizontal != 0 else 0.0
        except:
            return 0.0
            
    def compare_with_dataset(self, captured_image_path):
        """ë°ì´í„°ì…‹ ë¹„êµ"""
        try:
            known_encodings = []
            known_names = []
            
            dataset_files = []
            for ext in ["*.jpg", "*.jpeg", "*.png"]:
                dataset_files.extend(Path(self.DATASET_PATH).glob(ext))
            
            if not dataset_files:
                self.log_message("âŒ ë°ì´í„°ì…‹ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.", "ERROR")
                return None

            self.log_message(f"ğŸ“‚ ë°ì´í„°ì…‹ì—ì„œ {len(dataset_files)}ê°œ íŒŒì¼ ë¡œë“œ ì¤‘...")
            
            for file_path in dataset_files:
                try:
                    known_image = face_recognition.load_image_file(str(file_path))
                    encodings = face_recognition.face_encodings(known_image)
                    
                    if encodings:
                        known_encodings.append(encodings[0])
                        known_names.append(file_path.stem)
                        self.log_message(f"   âœ… {file_path.name} ë¡œë“œ ì™„ë£Œ")
                    else:
                        self.log_message(f"   â— {file_path.name} ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨", "WARNING")
                except Exception as e:
                    self.log_message(f"   â— {file_path.name} íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", "ERROR")
                    continue

            if not known_encodings:
                self.log_message("âŒ ìœ íš¨í•œ ì–¼êµ´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", "ERROR")
                return None

            unknown_image = face_recognition.load_image_file(captured_image_path)
            unknown_encodings = face_recognition.face_encodings(unknown_image)

            if not unknown_encodings:
                self.log_message("â— ìº¡ì²˜ëœ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "ERROR")
                return None

            unknown_encoding = unknown_encodings[0]
            
            results = face_recognition.compare_faces(known_encodings, unknown_encoding, 
                                                   tolerance=self.FACE_TOLERANCE)
            distances = face_recognition.face_distance(known_encodings, unknown_encoding)
            
            self.log_message("ğŸ“ ê±°ë¦¬ ê°’ (ê° ë“±ë¡ëœ ì–¼êµ´ê³¼ì˜ ê±°ë¦¬):")
            for name, dist in zip(known_names, distances):
                self.log_message(f"   ğŸ“Š {name}: {dist:.4f}")
            
            if True in results:
                idx = results.index(True)
                matched_name = known_names[idx]
                distance = distances[idx]
                self.log_message(f"âœ… [ë§¤ì¹­ ì„±ê³µ] {matched_name} (ê±°ë¦¬: {distance:.4f})", "SUCCESS")
                return matched_name
            else:
                min_distance = min(distances)
                self.log_message(f"âŒ [ë§¤ì¹­ ì‹¤íŒ¨] ìµœì†Œ ê±°ë¦¬: {min_distance:.4f} (ì„ê³„ê°’: {self.FACE_TOLERANCE})", "ERROR")
                self.log_message("ë“±ë¡ëœ ì¸ë¬¼ì´ ì•„ë‹™ë‹ˆë‹¤.", "ERROR")
                return None
                
        except Exception as e:
            self.log_message(f"âŒ ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", "ERROR")
            return None
            
    def get_landmarks_coords(self, face_landmarks, image_w, image_h):
        """ëœë“œë§ˆí¬ ì¢Œí‘œ ë³€í™˜"""
        coords = []
        for landmark in face_landmarks.landmark:
            x = int(landmark.x * image_w)
            y = int(landmark.y * image_h)
            coords.append([x, y])
        return np.array(coords)
        
    def get_head_direction(self, landmarks, image_w, image_h):
        """ë¨¸ë¦¬ ë°©í–¥ íŒë‹¨"""
        nose_tip = landmarks[self.NOSE_TIP]
        left_eye_left = landmarks[self.LEFT_EYE_LEFT]
        right_eye_right = landmarks[self.RIGHT_EYE_RIGHT]
        
        # ì–¼êµ´ ì¤‘ì‹¬ì„  ê³„ì‚°
        face_width = abs(right_eye_right[0] - left_eye_left[0])
        face_center_x = (left_eye_left[0] + right_eye_right[0]) / 2
        
        # ì¢Œìš° ë°©í–¥ íŒë‹¨
        offset_x = nose_tip[0] - face_center_x
        
        # ìƒí•˜ ë°©í–¥ íŒë‹¨
        eye_center_y = (left_eye_left[1] + right_eye_right[1]) / 2
        offset_y = nose_tip[1] - eye_center_y
        
        if face_width == 0:
            return "Forward", 0, 0
        
        # ì •ê·œí™”
        x_ratio = offset_x / face_width
        y_ratio = offset_y / face_width
        
        # ë°©í–¥ íŒë‹¨
        if y_ratio > self.Y_THRESHOLD:
            return "Down", x_ratio, y_ratio
        elif x_ratio > self.X_THRESHOLD:
            return "Right", x_ratio, y_ratio
        elif x_ratio < -self.X_THRESHOLD:
            return "Left", x_ratio, y_ratio
        else:
            return "Forward", x_ratio, y_ratio
            
    def get_gaze_ratio(self, eye_indices, landmarks, frame, gray):
        """ì‹œì„  ë°©í–¥ ê³„ì‚°"""
        h, w = frame.shape[:2]
        
        try:
            # ëˆˆ ì˜ì—­ ì¢Œí‘œ ê³„ì‚°
            eye_region = np.array([(int(landmarks[i][0] * w), int(landmarks[i][1] * h)) 
                                  for i in eye_indices], np.int32)
            
            # ë§ˆìŠ¤í¬ ìƒì„±
            mask = np.zeros((h, w), dtype=np.uint8)
            cv2.fillPoly(mask, [eye_region], 255)
            
            # ëˆˆ ì˜ì—­ ì¶”ì¶œ
            eye = cv2.bitwise_and(gray, gray, mask=mask)
            
            # ê²½ê³„ ì¢Œí‘œ ê³„ì‚°
            min_x = np.min(eye_region[:, 0])
            max_x = np.max(eye_region[:, 0])
            min_y = np.min(eye_region[:, 1])
            max_y = np.max(eye_region[:, 1])
            
            # ê²½ê³„ ê²€ì‚¬
            if min_x >= max_x or min_y >= max_y or min_x < 0 or min_y < 0 or max_x >= w or max_y >= h:
                return 1.0
            
            # ëˆˆ ì˜ì—­ í¬ë¡­
            gray_eye = eye[min_y:max_y, min_x:max_x]
            
            if gray_eye.size == 0:
                return 1.0
            
            # ì„ê³„ê°’ ì ìš©
            _, threshold_eye = cv2.threshold(gray_eye, 70, 255, cv2.THRESH_BINARY)
            
            th_h, th_w = threshold_eye.shape
            
            if th_w < 2:
                return 1.0
            
            # ì¢Œìš° ì˜ì—­ì˜ í°ìƒ‰ í”½ì…€ ìˆ˜ ê³„ì‚°
            left_white = cv2.countNonZero(threshold_eye[:, 0:int(th_w / 2)])
            right_white = cv2.countNonZero(threshold_eye[:, int(th_w / 2):])
            
            if left_white == 0 or right_white == 0:
                return 1.0
            else:
                return left_white / right_white
                
        except Exception as e:
            return 1.0
            
    def reset_violation_states(self):
        """ìœ„ë°˜ ìƒíƒœ ì´ˆê¸°í™”"""
        self.is_head_abnormal = False
        self.head_abnormal_start_time = time.time()
        self.is_head_violation = False
        
        self.is_multiple_faces = False
        self.multiple_faces_start_time = time.time()
        self.is_multiple_faces_violation = False
        
        self.is_no_face = False
        self.no_face_start_time = time.time()
        self.is_no_face_violation = False
        
        self.is_gaze_abnormal = False
        self.gaze_abnormal_start_time = time.time()
        self.is_gaze_violation = False
        
    def update_violation_states(self, face_count, head_direction, gaze_ratio):
        """ìœ„ë°˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        current_time = time.time()
        
        # ì‹œí—˜ì´ ì´ë¯¸ ì¤‘ë‹¨ëœ ê²½ìš° ì²˜ë¦¬ ì¤‘ì§€
        if self.exam_terminated:
            return
        
        # 1. ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€ - ì¦‰ì‹œ ì¤‘ë‹¨
        current_multiple_faces = face_count > 1
        if current_multiple_faces != self.is_multiple_faces:
            self.is_multiple_faces = current_multiple_faces
            self.multiple_faces_start_time = current_time
            self.is_multiple_faces_violation = False
        
        if self.is_multiple_faces:
            duration = current_time - self.multiple_faces_start_time
            if duration >= self.SUSTAINED_TIME and not self.is_multiple_faces_violation:
                self.is_multiple_faces_violation = True
                # ë¶€ì •í–‰ìœ„ ì•Œë¦¼ ì¶œë ¥
                self.print_violation_alert("ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€", f"ê°ì§€ëœ ì–¼êµ´ ìˆ˜: {face_count}ëª…", 
                                         is_start=True, duration=duration)
                # ì‹œí—˜ ì¦‰ì‹œ ì¤‘ë‹¨
                self.terminate_exam(f"ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€ ({face_count}ëª…)")
                return
            elif duration < self.SUSTAINED_TIME and duration > 0.5:
                self.print_warning("ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€", f"{face_count}ëª… ê°ì§€ë¨", duration)
        
        # 2. í™”ë©´ ì´íƒˆ ê°ì§€ - ì¦‰ì‹œ ì¤‘ë‹¨
        current_no_face = face_count == 0
        if current_no_face != self.is_no_face:
            self.is_no_face = current_no_face
            self.no_face_start_time = current_time
            self.is_no_face_violation = False
        
        if self.is_no_face:
            duration = current_time - self.no_face_start_time
            if duration >= self.SUSTAINED_TIME and not self.is_no_face_violation:
                self.is_no_face_violation = True
                # ë¶€ì •í–‰ìœ„ ì•Œë¦¼ ì¶œë ¥
                self.print_violation_alert("í™”ë©´ ì´íƒˆ", "ì–¼êµ´ ê°ì§€ ë¶ˆê°€ - í™”ë©´ì—ì„œ ì™„ì „íˆ ì´íƒˆ", 
                                         is_start=True, duration=duration)
                # ì‹œí—˜ ì¦‰ì‹œ ì¤‘ë‹¨
                self.terminate_exam("í™”ë©´ ì´íƒˆ (ì–¼êµ´ ê°ì§€ ë¶ˆê°€)")
                return
            elif duration < self.SUSTAINED_TIME and duration > 0.5:
                self.print_warning("í™”ë©´ ì´íƒˆ", "ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ", duration)
        
        # 3. ê³ ê°œ ë°©í–¥ ê°ì§€ - ê²½ê³  í›„ ì¤‘ë‹¨
        current_head_abnormal = head_direction in ["Left", "Right", "Down"]
        if current_head_abnormal != self.is_head_abnormal:
            if not current_head_abnormal and self.is_head_violation:
                # ìœ„ë°˜ ìƒíƒœ ì¢…ë£Œ
                total_duration = current_time - self.head_abnormal_start_time
                self.log_message(f"ê³ ê°œ ë°©í–¥ ì •ìƒí™” (ì§€ì†ì‹œê°„: {total_duration:.1f}ì´ˆ)", "SUCCESS")
            
            self.is_head_abnormal = current_head_abnormal
            self.head_abnormal_start_time = current_time
            self.is_head_violation = False
        
        if self.is_head_abnormal:
            duration = current_time - self.head_abnormal_start_time
            if duration >= self.SUSTAINED_TIME and not self.is_head_violation:
                self.is_head_violation = True
                # ê²½ê³  ë°œê¸‰
                is_terminated = self.issue_warning("ê³ ê°œ ë°©í–¥", f"ë°©í–¥: {head_direction}")
                if is_terminated:
                    return
            elif duration < self.SUSTAINED_TIME and duration > 0.5:
                self.print_warning("ê³ ê°œ ë°©í–¥", f"{head_direction} ë°©í–¥ìœ¼ë¡œ ì›€ì§ì„", duration)
        
        # 4. ì‹œì„  ì´íƒˆ ê°ì§€ - ê²½ê³  í›„ ì¤‘ë‹¨
        if self.gaze_baseline is not None and gaze_ratio != 1:
            current_gaze_abnormal = (gaze_ratio < self.gaze_baseline - self.GAZE_MARGIN or 
                                   gaze_ratio > self.gaze_baseline + self.GAZE_MARGIN)
            
            if current_gaze_abnormal != self.is_gaze_abnormal:
                if not current_gaze_abnormal and self.is_gaze_violation:
                    # ìœ„ë°˜ ìƒíƒœ ì¢…ë£Œ
                    total_duration = current_time - self.gaze_abnormal_start_time
                    self.log_message(f"ì‹œì„  ì •ìƒí™” (ì§€ì†ì‹œê°„: {total_duration:.1f}ì´ˆ)", "SUCCESS")
                
                self.is_gaze_abnormal = current_gaze_abnormal
                self.gaze_abnormal_start_time = current_time
                self.is_gaze_violation = False
            
            if self.is_gaze_abnormal:
                duration = current_time - self.gaze_abnormal_start_time
                if duration >= self.SUSTAINED_TIME and not self.is_gaze_violation:
                    self.is_gaze_violation = True
                    direction = "ì™¼ìª½" if gaze_ratio < self.gaze_baseline else "ì˜¤ë¥¸ìª½"
                    # ê²½ê³  ë°œê¸‰
                    is_terminated = self.issue_warning("ì‹œì„  ì´íƒˆ", f"{direction} ë°©í–¥ìœ¼ë¡œ ì‹œì„  ì´íƒˆ")
                    if is_terminated:
                        return
                elif duration < self.SUSTAINED_TIME and duration > 0.5:
                    direction = "ì™¼ìª½" if gaze_ratio < self.gaze_baseline else "ì˜¤ë¥¸ìª½"
                    deviation = abs(gaze_ratio - self.gaze_baseline)
                    self.print_warning("ì‹œì„  ì´íƒˆ", f"{direction} ì‹œì„  (í¸ì°¨: {deviation:.2f})", duration)
                    
    def terminate_exam(self, reason):
        """ì‹œí—˜ ì¤‘ë‹¨"""
        self.exam_terminated = True
        self.termination_reason = reason
        
        self.log_message("ğŸš¨ ë¶€ì •í–‰ìœ„ íƒì§€! ì‹œí—˜ ì¦‰ì‹œ ì¤‘ë‹¨! ğŸš¨", "ERROR")
        self.log_message(f"ì‚¬ìœ : {reason}", "ERROR")
        self.log_message("ì‹¬ê°í•œ ë¶€ì •í–‰ìœ„ê°€ íƒì§€ë˜ì–´ ì‹œí—˜ì´ ì¦‰ì‹œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.", "ERROR")
        self.log_message("ì´ ê²°ê³¼ëŠ” ì‹œí—˜ ê´€ë¦¬ìì—ê²Œ ë³´ê³ ë©ë‹ˆë‹¤.", "ERROR")
        
        speak_tts("ì‹¬ê°í•œ ë¶€ì •í–‰ìœ„ê°€ íƒì§€ë˜ì–´ ì‹œí—˜ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        
        # ë¡œê·¸ ê¸°ë¡
        self.log_violation("ë¶€ì •í–‰ìœ„-ì‹œí—˜ì¤‘ë‹¨", reason)
        
    def issue_warning(self, warning_type, details):
        """ê²½ê³  ë°œê¸‰ (í†µí•© 5íšŒ ì‹œìŠ¤í…œ)"""
        # ê°œë³„ ê²½ê³  íšŸìˆ˜ ì¦ê°€ (í‘œì‹œìš©)
        if warning_type == "ê³ ê°œ ë°©í–¥":
            self.head_warnings += 1
        elif warning_type == "ì‹œì„  ì´íƒˆ":
            self.gaze_warnings += 1
        
        # í†µí•© ê²½ê³  íšŸìˆ˜ ì¦ê°€
        self.total_warnings += 1
        remaining = self.MAX_WARNINGS - self.total_warnings
        
        speak_tts(f"{warning_type}ë¶€ì •í–‰ìœ„ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        self.log_message(f"âš ï¸  ê²½ê³  {self.total_warnings}/{self.MAX_WARNINGS} - {warning_type}", "WARNING")
        self.log_message(f"ìƒì„¸: {details}", "WARNING")
        
        if self.total_warnings >= self.MAX_WARNINGS:
            self.log_message(f"ğŸš¨ ì´ {self.MAX_WARNINGS}íšŒ ê²½ê³  ëˆ„ì ! ë¶€ì •í–‰ìœ„ë¡œ íŒì •ë©ë‹ˆë‹¤.", "ERROR")
            self.terminate_exam(f"ê²½ê³  {self.MAX_WARNINGS}íšŒ ëˆ„ì  (ê³ ê°œ: {self.head_warnings}íšŒ, ì‹œì„ : {self.gaze_warnings}íšŒ)")
            return True
        else:
            self.log_message(f"ë‚¨ì€ ê²½ê³ : {remaining}íšŒ (ê³ ê°œ: {self.head_warnings}íšŒ, ì‹œì„ : {self.gaze_warnings}íšŒ)")
        
        # ë¡œê·¸ ê¸°ë¡
        self.log_violation(f"ê²½ê³ -{warning_type}", details)
        return False
        
    def print_violation_alert(self, violation_type, details, is_start=True, duration=0):
        """ìœ„ë°˜ ì‚¬í•­ í„°ë¯¸ë„ ì•Œë¦¼"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        if is_start:
            self.log_message("ğŸš¨ ìœ„ë°˜ ê°ì§€! ğŸš¨", "ERROR")
            self.log_message(f"ì‹œê°„: {timestamp} ìœ í˜•: {violation_type}", "ERROR")
            self.log_message(f"ìƒì„¸: {details}", "ERROR")
            self.log_message(f"ì§€ì†ì‹œê°„: {duration:.1f}ì´ˆ", "ERROR")
            
            self.total_violations += 1
            self.log_violation(violation_type, details)
            
        else:
            self.log_message(f"ìœ„ë°˜ ì¢…ë£Œ: {violation_type} (ì´ ì§€ì†ì‹œê°„: {duration:.1f}ì´ˆ)", "SUCCESS")
            
    def print_warning(self, warning_type, details, duration):
        """ê²½ê³  ì‚¬í•­ í„°ë¯¸ë„ ì¶œë ¥"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        progress = min(duration / self.SUSTAINED_TIME, 1.0) * 100
        bar_length = 20
        filled_length = int(bar_length * progress / 100)
        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
        
        self.log_message(f"âš ï¸  {warning_type}: {details} [{bar}] {progress:.0f}% ({duration:.1f}s)", "WARNING")
        
    def log_violation(self, violation_type, details):
        """ìœ„ë°˜ ì‚¬í•­ ë¡œê·¸ ê¸°ë¡"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = {
            "timestamp": timestamp,
            "user": self.authenticated_user,
            "type": violation_type,
            "details": details,
            "exam_duration": int(time.time() - self.exam_start_time) if self.exam_start_time else 0,
            "total_warnings": self.total_warnings,
            "head_warnings": self.head_warnings,
            "gaze_warnings": self.gaze_warnings
        }
        self.violation_log.append(log_entry)
        self.total_violations += 1
        
    def draw_status_info(self, frame, face_count, head_direction, gaze_ratio, x_ratio, y_ratio):
        """í™”ë©´ì— ìƒíƒœ ì •ë³´ í‘œì‹œ"""
        current_time = time.time()
        exam_duration = int(current_time - self.exam_start_time) if self.exam_start_time else 0
        
        # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        cv2.putText(frame, f"User: {self.authenticated_user}", (30, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Exam Time: {exam_duration}s", (30, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Faces: {face_count}", (30, 90),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Head: {head_direction}", (30, 120),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        if self.gaze_baseline is not None:
            cv2.putText(frame, f"Gaze: {gaze_ratio:.2f} (Base: {self.gaze_baseline:.2f})", (30, 150),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        else:
            cv2.putText(frame, f"Gaze: {gaze_ratio:.2f} (Calibrating...)", (30, 150),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ê²½ê³  íšŸìˆ˜ í‘œì‹œ (í†µí•©)
        warning_color = (0, 255, 255) if self.total_warnings < self.MAX_WARNINGS else (0, 0, 255)
        cv2.putText(frame, f"Total Warnings: {self.total_warnings}/{self.MAX_WARNINGS}", (30, 180),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, warning_color, 2)
        
        cv2.putText(frame, f"Head: {self.head_warnings}, Gaze: {self.gaze_warnings}", (30, 210),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ìœ„ë°˜ ìƒíƒœ í‘œì‹œ
        y_offset = 240
        
        violations = []
        if self.is_multiple_faces_violation:
            violations.append("Multiple Faces")
        if self.is_no_face_violation:
            violations.append("No Face")
        if self.is_head_violation:
            violations.append(f"Head: {head_direction}")
        if self.is_gaze_violation:
            violations.append("Gaze Direction")
        
        if violations:
            cv2.putText(frame, f"VIOLATIONS: {', '.join(violations)}", (30, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        
        # ì‹œí—˜ ì¤‘ë‹¨ ìƒíƒœ í‘œì‹œ
        if self.exam_terminated:
            # ë¶€ì •í–‰ìœ„ íƒì§€ë¡œ ì¸í•œ ì¤‘ë‹¨ ê°•ì¡° í‘œì‹œ
            cv2.putText(frame, "CHEATING DETECTED!", (30, y_offset + 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
            cv2.putText(frame, "EXAM TERMINATED", (30, y_offset + 80),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
            cv2.putText(frame, f"Reason: {self.termination_reason}", (30, y_offset + 120),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # í™”ë©´ ì „ì²´ì— ê²½ê³  í…Œë‘ë¦¬ í‘œì‹œ
            cv2.rectangle(frame, (10, 10), (frame.shape[1]-10, frame.shape[0]-10), (0, 0, 255), 5)
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ í‘œì‹œ
        if self.gaze_baseline is None:
            progress = (self.frame_count / self.BASELINE_FRAMES) * 100
            cv2.putText(frame, f"Eye Calibration: {self.frame_count}/{self.BASELINE_FRAMES} ({progress:.0f}%)", 
                       (30, frame.shape[0] - 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            cv2.putText(frame, "Look forward and stay still", 
                       (30, frame.shape[0] - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ìœ„ë°˜ íšŸìˆ˜ í‘œì‹œ
        cv2.putText(frame, f"Total Violations: {self.total_violations}", 
                   (frame.shape[1] - 300, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255) if self.total_violations > 0 else (0, 255, 0), 2)
        
    # =====================================
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    # =====================================
        
    def log_message(self, message, level="INFO"):
        """ë¡œê·¸ ë©”ì‹œì§€ (Queue ì—†ì´ ì§ì ‘)"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted = f"[{timestamp}] {message}\n"
        
        self.log_text.insert(tk.END, formatted)
        
        # ìƒ‰ìƒ ì ìš©
        if level == "ERROR":
            color = "red"
        elif level == "WARNING":
            color = "orange"
        elif level == "SUCCESS":
            color = "green"
        else:
            color = "black"
            
        # ìŠ¤í¬ë¡¤
        self.log_text.see(tk.END)
        
        # ë¼ì¸ ìˆ˜ ì œí•œ
        lines = int(self.log_text.index('end-1c').split('.')[0])
        if lines > 500:
            self.log_text.delete('1.0', '100.0')
            
    def run(self):
        """GUI ì‹¤í–‰"""
        self.log_message("ğŸ¤– AI ì‹œí—˜ ê°ë…ê´€ v2.6 (ë‹¨ìˆœí™”) ì‹œì‘", "SUCCESS")
        self.log_message("Queue ì‹œìŠ¤í…œì„ ì œê±°í•˜ê³  ì§ì ‘ GUI ì—…ë°ì´íŠ¸ë¡œ ë‹¨ìˆœí™”í–ˆìŠµë‹ˆë‹¤.")
        self.log_message("ì›ë³¸ ê°ë… ë¡œì§ì€ 100% ë³´ì¡´ë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.log_message("ë¶€ì •í–‰ìœ„ íƒì§€ ë° TTS ê¸°ëŠ¥ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        self.root.mainloop()
        
    def on_closing(self):
        """ì¢…ë£Œ ì²˜ë¦¬"""
        if self.is_running:
            if messagebox.askokcancel("ì¢…ë£Œ", "ì‹œí—˜ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì •ë§ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?"):
                self.stop_system()
                self.root.destroy()
        else:
            self.root.destroy()

# =====================================
# TTS í•¨ìˆ˜
# =====================================

def tts_worker_thread():
    """TTS ì „ìš© ì¬ìƒ ë£¨í”„ (í•œ ë²ˆì— í•˜ë‚˜ì”© ì²˜ë¦¬)"""
    last_text = ""
    last_time = 0

    while True:
        text = tts_queue.get()
        now = time.time()

        # ì¤‘ë³µ ë°©ì§€ (ê°™ì€ ë¬¸ì¥ì„ 3ì´ˆ ì´ë‚´ ë°˜ë³µ ê¸ˆì§€)
        if text == last_text and now - last_time < 3:
            print(f"[TTS] ì¤‘ë³µ ìƒëµ: {text}")
            continue

        last_text = text
        last_time = now

        try:
            print(f"[TTS] ì¬ìƒ: {text}")
            tts = gTTS(text=text, lang='ko')
            tts_path = "tts_output.mp3"
            tts.save(tts_path)
            subprocess.run(["mpg123", tts_path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            os.remove(tts_path)
        except Exception as e:
            print(f"[TTS ì˜¤ë¥˜] {e}")


def speak_tts(text):
    """TTS ìš”ì²­ì„ íì— ì¶”ê°€"""
    if not TTS_AVAILABLE:
        return
    tts_queue.put(text)

# ì‹¤í–‰
if __name__ == "__main__":
    try:
        threading.Thread(target=tts_worker_thread, daemon=True).start()
        app = SimpleExamSupervisor()
        app.run()
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")
        print("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        print("pip install opencv-python mediapipe face-recognition pillow gtts")
        sys.exit(1)
