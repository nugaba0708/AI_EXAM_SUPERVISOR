import cv2
import mediapipe as mp
import numpy as np
import face_recognition
import time
import os
import json
from datetime import datetime

# EAR ê³„ì‚° í•¨ìˆ˜
def calculate_ear(landmarks, eye_indices):
    left = np.array([landmarks[eye_indices[0]].x, landmarks[eye_indices[0]].y])
    right = np.array([landmarks[eye_indices[3]].x, landmarks[eye_indices[3]].y])
    top = (np.array([landmarks[eye_indices[1]].x, landmarks[eye_indices[1]].y]) +
           np.array([landmarks[eye_indices[2]].x, landmarks[eye_indices[2]].y])) / 2
    bottom = (np.array([landmarks[eye_indices[4]].x, landmarks[eye_indices[4]].y]) +
              np.array([landmarks[eye_indices[5]].x, landmarks[eye_indices[5]].y])) / 2
    horizontal = np.linalg.norm(left - right)
    vertical = np.linalg.norm(top - bottom)
    return vertical / horizontal

# ëˆˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
LEFT_EYE = [362, 385, 387, 263, 373, 380]
RIGHT_EYE = [33, 160, 158, 133, 153, 144]

# ì–¼êµ´ ì¸ì¦ í•¨ìˆ˜ (ìˆ˜ì •ë¨)
def authenticate_face(img_path, dataset_path="./dataset"):
    known_encodings = []
    known_names = []

    for filename in os.listdir(dataset_path):
        if filename.endswith(('.jpg', '.png')):
            image = face_recognition.load_image_file(os.path.join(dataset_path, filename))
            encodings = face_recognition.face_encodings(image)
            if encodings:
                known_encodings.append(encodings[0])
                known_names.append(os.path.splitext(filename)[0])

    unknown_image = face_recognition.load_image_file(img_path)
    unknown_encodings = face_recognition.face_encodings(unknown_image)

    result_data = {}

    if unknown_encodings:
        results = face_recognition.compare_faces(known_encodings, unknown_encodings[0], tolerance=0.4)
        distances = face_recognition.face_distance(known_encodings, unknown_encodings[0])

        if True in results:
            idx = results.index(True)
            print(f"âœ… ì‹ ì› í™•ì¸ ì„±ê³µ: {known_names[idx]} (ê±°ë¦¬: {distances[idx]:.4f})")
            result_data = {
                "authenticated": True,
                "name": known_names[idx],
                "distance": float(f"{distances[idx]:.4f}")
            }
        else:
            print("âŒ ì‹ ì› í™•ì¸ ì‹¤íŒ¨: ë“±ë¡ëœ ì¸ë¬¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
            result_data = {
                "authenticated": False,
                "reason": "ë“±ë¡ëœ ì¸ë¬¼ì´ ì•„ë‹˜"
            }
    else:
        print("â— ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨: ì´ë¯¸ì§€ì— ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        result_data = {
            "authenticated": False,
            "reason": "ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨"
        }

    return result_data

# ëˆˆ ê¹œë¹¡ì„ ê°ì§€ ë° ì‹ ì› í™•ì¸
def detect_blink_and_authenticate(dataset_path="./dataset"):
    cap = cv2.VideoCapture(2)  # ì¹´ë©”ë¼ ì¸ë±ìŠ¤ í™˜ê²½ì— ë§ê²Œ ë³€ê²½
    BLINK_THRESHOLD = 0.21
    BLINK_REQUIRED = 2
    DURATION = 6  # ê°ì§€ ì‹œê°„(ì´ˆ)
    MAX_HISTORY = 100

    mp_face_mesh = mp.solutions.face_mesh

    with mp_face_mesh.FaceMesh(
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as face_mesh:

        while True:
            print("âŒ› ëŒ€ê¸° ì¤‘: 'c' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ê°ì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ('q' í‚¤ë¡œ ì¢…ë£Œ)")

            # ëŒ€ê¸° ë£¨í”„
            while True:
                ret, frame = cap.read()
                if not ret:
                    continue

                cv2.putText(frame, "Press 'c' to start blink detection", (30, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

                cv2.imshow('Waiting', frame)
                key = cv2.waitKey(1) & 0xFF
                if key == ord('c'):
                    print("â–¶ ëˆˆ ê¹œë¹¡ì„ ê°ì§€ ì‹œì‘")
                    break
                elif key == ord('q'):
                    print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    cap.release()
                    cv2.destroyAllWindows()
                    return

            blink_count = 0
            blink_flag = False
            ear_history = []
            ear_log_data = []  # EAR JSON ë¡œê·¸ìš© ë¦¬ìŠ¤íŠ¸
            frame_to_save = None
            start_time = time.time()

            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = face_mesh.process(rgb)
                ear = None

                if results.multi_face_landmarks:
                    for face_landmarks in results.multi_face_landmarks:
                        landmarks = face_landmarks.landmark
                        left_ear = calculate_ear(landmarks, LEFT_EYE)
                        right_ear = calculate_ear(landmarks, RIGHT_EYE)
                        ear = (left_ear + right_ear) / 2.0

                        # EAR í…ìŠ¤íŠ¸ ì¶œë ¥
                        cv2.putText(frame, f"EAR: {ear:.3f}", (30, 30),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                        # ëˆˆ ê¹œë¹¡ì„ ê°ì§€
                        if ear < BLINK_THRESHOLD and not blink_flag:
                            blink_count += 1
                            blink_flag = True
                            print(f"ğŸ‘ ê¹œë¹¡ì„ ê°ì§€ë¨! ì´ {blink_count}íšŒ")
                        elif ear >= BLINK_THRESHOLD:
                            blink_flag = False

                        frame_to_save = frame.copy()

                # EAR ê¸°ë¡
                if ear is not None:
                    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    ear_log_data.append({"timestamp": timestamp, "ear": round(ear, 4)})

                    ear_history.append(ear)
                    if len(ear_history) > MAX_HISTORY:
                        ear_history.pop(0)

                    # EAR ê·¸ë˜í”„ (ì œê±°í•˜ê¸¸ ì›í•˜ì‹œë©´ ì´ ë¶€ë¶„ ì‚­ì œí•˜ì„¸ìš”)
                    for i in range(1, len(ear_history)):
                        pt1 = (frame.shape[1] - MAX_HISTORY + i - 1, 140 - int(ear_history[i - 1] * 100))
                        pt2 = (frame.shape[1] - MAX_HISTORY + i, 140 - int(ear_history[i] * 100))
                        cv2.line(frame, pt1, pt2, (255, 0, 0), 1)

                    threshold_y = 140 - int(BLINK_THRESHOLD * 100)
                    cv2.line(frame, (frame.shape[1] - MAX_HISTORY, threshold_y),
                             (frame.shape[1], threshold_y), (0, 0, 255), 1)
                    cv2.putText(frame, "EAR Graph", (frame.shape[1] - MAX_HISTORY, 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                cv2.imshow('Blink Detection', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    cap.release()
                    cv2.destroyAllWindows()
                    return

                if time.time() - start_time > DURATION:
                    break

            cv2.destroyAllWindows()

            # ê¹œë¹¡ì„ ê²°ê³¼ í‰ê°€ ë° ì‹ ì› í™•ì¸
            if blink_count >= BLINK_REQUIRED and frame_to_save is not None:
                print("âœ… ì‹¤ì œ ì‚¬ëŒìœ¼ë¡œ íŒë³„ë¨. ì‹ ì› í™•ì¸ ì‹œì‘...")
                img_path = "capture.jpg"
                cv2.imwrite(img_path, frame_to_save)

                auth_result = authenticate_face(img_path, dataset_path)

                # ì¸ì¦ ê²°ê³¼ë¥¼ ë¡œê·¸ì— ì¶”ê°€
                final_log = {
                    "ear_log": ear_log_data,
                    "blink_count": blink_count,
                    "authentication": auth_result,
                    "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }

                # ë¡œê·¸ ì €ì¥ í´ë”ì™€ íŒŒì¼ëª… ì„¤ì •
                log_dir = "./log"
                os.makedirs(log_dir, exist_ok=True)

                # ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸° ë°©ì§€ ìœ„í•´ íŒŒì¼ëª…ì— ì‹œê°„ ì¶”ê°€
                filename = datetime.now().strftime("ear_log_%Y%m%d_%H%M%S.json")
                filepath = os.path.join(log_dir, filename)

                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(final_log, f, indent=2, ensure_ascii=False)
                    print(f"ğŸ“ EAR ë° ì¸ì¦ ë¡œê·¸ê°€ '{filepath}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                break
            else:
                print("âŒ ì‚¬ì§„ìœ¼ë¡œ íŒë³„ë¨ (ëˆˆ ê¹œë¹¡ì„ ê°ì§€ë˜ì§€ ì•ŠìŒ). ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\n")
                time.sleep(2)


if __name__ == "__main__":
    detect_blink_and_authenticate(dataset_path="./dataset")
